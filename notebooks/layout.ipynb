{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe26d8a-8d8c-4fd4-8d82-6157de01ef09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructing documents: 100%|██████████| 32/32 [00:00<00:00, 1943.69it/s]\n",
      "OCR: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import segment\n",
    "importlib.reload(segment)\n",
    "from segment import load_report_with_images, get_docs_with_ocr\n",
    "from doctr.models import ocr_predictor\n",
    "\n",
    "ocr_model = ocr_predictor(det_arch='db_resnet50', reco_arch='crnn_vgg16_bn', pretrained=True).cuda()\n",
    "items = load_report_with_images(limit=32)\n",
    "print(\"Loaded:\", len(items))\n",
    "docs = get_docs_with_ocr(items, ocr_model)\n",
    "print(\"Parsed:\", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38cf75ab-2245-4acd-a980-bf0aae7d06fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import importlib\n",
    "import visualize\n",
    "importlib.reload(visualize)\n",
    "from visualize import visualize_word_boxes\n",
    "\n",
    "data = docs[1]\n",
    "img = visualize_word_boxes(data[\"image_path\"], data[\"boxes\"], data[\"labels\"])\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# plt.imshow(img)\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f13056d1-eaae-4d7d-bef6-10f4f884921c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056a5c5af91c4202ae522849c2ef9772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c81ba9e46d4c77ae9429b63497ea8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import LayoutLMv3Processor, LayoutLMv3ForTokenClassification\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import torch\n",
    "from datasets import Features, Sequence, ClassLabel, Value, Array2D, Array3D\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n",
    "\n",
    "# we need to define custom features\n",
    "# features = Features({\n",
    "#     'image': Array3D(dtype=\"int64\", shape=(3, 224, 224)),\n",
    "#     'input_ids': Sequence(feature=Value(dtype='int64')),\n",
    "#     'attention_mask': Sequence(Value(dtype='int64')),\n",
    "#     'token_type_ids': Sequence(Value(dtype='int64')),\n",
    "#     'bbox': Array2D(dtype=\"int64\", shape=(512, 4)),\n",
    "#     'labels': Sequence(ClassLabel(names=labels)),\n",
    "# })\n",
    "\n",
    "def normalize_doc(d):\n",
    "    h, w = d['dimensions']\n",
    "    for box in d['boxes']:\n",
    "        box[0] = int(box[0] / w * 1000)\n",
    "        box[1] = int(box[1] / h * 1000)\n",
    "        box[2] = int(box[2] / w * 1000)\n",
    "        box[3] = int(box[3] / h * 1000)\n",
    "    return {\n",
    "        \"words\": d[\"words\"],          # list of strings\n",
    "        \"boxes\": d[\"boxes\"],\n",
    "        \"labels\": d[\"labels\"],        # list of ints\n",
    "        \"image_path\": d[\"image_path\"]\n",
    "    }\n",
    "\n",
    "\n",
    "def preprocess_data(examples):\n",
    "  images = [Image.open(path).convert(\"RGB\") for path in examples['image_path']]\n",
    "  words = examples['words']\n",
    "  boxes = examples['boxes']\n",
    "  word_labels = examples['labels']\n",
    "  \n",
    "  encoded_inputs = processor(images, words, boxes=boxes, word_labels=word_labels,\n",
    "                             padding=\"max_length\", truncation=True)\n",
    "  \n",
    "  return encoded_inputs\n",
    "\n",
    "rows = [normalize_doc(d) for d in docs]\n",
    "ds = Dataset.from_list(rows)\n",
    "ds = ds.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = ds['train'].map(preprocess_data, batched=True, remove_columns=ds['train'].column_names)\n",
    "test_dataset = ds['test'].map(preprocess_data, batched=True, remove_columns=ds['test'].column_names)\n",
    "\n",
    "train_dataset.set_format(type=\"torch\")\n",
    "test_dataset.set_format(type=\"torch\")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb0e32af-f579-413e-8033-84b50bde3fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import LayoutLMv3ForTokenClassification\n",
    "\n",
    "device = 'cuda'\n",
    "# load the fine-tuned model from the hub\n",
    "model = LayoutLMv3ForTokenClassification.from_pretrained('microsoft/layoutlmv3-base', num_labels=128)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b835c43-6385-4e13-9ea2-64437d8ae66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:evaluate.loading:Using the latest cached version of the module from /home/compiling-ganesh/24m0797/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--accuracy/f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Tue Nov 25 11:30:05 2025) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n",
      "WARNING:evaluate.loading:Using the latest cached version of the module from /home/compiling-ganesh/24m0797/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--f1/34c46321f42186df33a6260966e34a368f14868d9cc2ba47d142112e2800d233 (last modified on Tue Nov 25 11:27:07 2025) since it couldn't be found locally at evaluate-metric--f1, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "metric_f1 = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "657dece2-13b6-4841-95ba-b7555c1c712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Metrics\n",
    "return_entity_level_metrics = True\n",
    "\n",
    "id2label = [str(n) for n in np.arange(128)]\n",
    "label2id = {label: idx for idx, label in enumerate(id2label)}\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    \n",
    "    # Flatten but remove -100\n",
    "    true_preds = []\n",
    "    true_labels = []\n",
    "    \n",
    "    for pred_row, label_row in zip(preds, labels):\n",
    "        for p_i, l_i in zip(pred_row, label_row):\n",
    "            if l_i != -100:       # keep only real tokens\n",
    "                true_preds.append(int(p_i))\n",
    "                true_labels.append(int(l_i))\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": metric_acc.compute(predictions=true_preds, references=true_labels)['accuracy'],\n",
    "        \"f1_macro\": metric_f1.compute(predictions=true_preds, references=true_labels, average=\"macro\")['f1']\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab6d2875-9b47-4c29-b6d4-cd704eba0fa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/compiling-ganesh/24m0797/workspace/doctr-dit/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:1621: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:15, Epoch 14/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.03136849403381348, metrics={'train_runtime': 20.8816, 'train_samples_per_second': 38.311, 'train_steps_per_second': 4.789, 'total_flos': 106282195353600.0, 'train_loss': 0.03136849403381348, 'epoch': 14.285714285714286})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "class LayoutTrainer(Trainer):\n",
    "    def get_train_dataloader(self):\n",
    "      return train_dataloader\n",
    "\n",
    "    def get_test_dataloader(self, test_dataset):\n",
    "      return test_dataloader\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"../models/layoutlmv3-finetuned\", # name of directory to store the checkpoints\n",
    "    max_steps=100, # we train for a maximum of 1,000 batches\n",
    "    warmup_ratio=0.1, # we warmup a bit\n",
    "    fp16=True, # we use mixed precision (less memory consumption)\n",
    "    push_to_hub=False, # after training, we'd like to push our model to the hub\n",
    ")\n",
    "\n",
    "# Initialize our Trainer\n",
    "trainer = LayoutTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37feafee-4a29-4b0d-a9a5-3ec8cfdda332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/compiling-ganesh/24m0797/workspace/doctr-dit/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:1621: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 7.942758560180664, 'test_accuracy': 0.11551724137931034, 'test_f1_macro': 0.03160774300408237, 'test_runtime': 1.0949, 'test_samples_per_second': 3.653, 'test_steps_per_second': 0.913}\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, metrics = trainer.predict(test_dataset)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3c923d6-4e5d-4150-baab-eba940c46cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-100,    0,    0, ..., -100, -100, -100],\n",
       "       [-100,    0,    0, ..., -100, -100, -100],\n",
       "       [-100,    0,    1, ...,    7,    7, -100],\n",
       "       [-100,    0,    0, ..., -100, -100, -100]], shape=(4, 512))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2592fb79-474a-4fcd-b0c3-2e637c03ef82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:evaluate.loading:Using the latest cached version of the module from /home/compiling-ganesh/24m0797/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Tue Nov 25 11:04:05 2025) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
