{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6fef4a0-1829-4c70-9997-42cda07c2c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading docs from cache...\n",
      "Loaded from cache: 995\n",
      "Processed Docs: 995\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import segment\n",
    "importlib.reload(segment)\n",
    "from segment import load_report_with_images, get_docs_with_ocr\n",
    "from doctr.models import ocr_predictor\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "CACHE_PATH = \"../data/cache/ocr_docs3.pkl\"\n",
    "\n",
    "if os.path.exists(CACHE_PATH):\n",
    "    print(\"Loading docs from cache...\")\n",
    "    with open(CACHE_PATH, \"rb\") as f:\n",
    "        docs = pickle.load(f)\n",
    "    print(\"Loaded from cache:\", len(docs))\n",
    "else:\n",
    "    ocr_model = ocr_predictor(det_arch='db_resnet50', reco_arch='crnn_vgg16_bn', pretrained=True).cuda()\n",
    "    items = load_report_with_images(limit=32)\n",
    "    print(\"Loaded:\", len(items))\n",
    "    docs = get_docs_with_ocr(items, ocr_model)\n",
    "    os.makedirs(os.path.dirname(CACHE_PATH), exist_ok=True)\n",
    "    with open(CACHE_PATH, \"wb\") as f:\n",
    "        pickle.dump(docs, f)\n",
    "    print(\"Saved docs to cache:\", CACHE_PATH)\n",
    "\n",
    "docs = [doc for doc in docs if len(doc['segments']) < 120]\n",
    "print(\"Processed Docs:\", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b424d48-af9f-4288-b417-bef6d760e174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO segment-only dataset created! ../data/yolo_segments\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def convert_segments_to_yolo(docs, out_dir=\"../data/yolo_segments\"):\n",
    "    os.makedirs(f\"{out_dir}/images\", exist_ok=True)\n",
    "    os.makedirs(f\"{out_dir}/labels\", exist_ok=True)\n",
    "\n",
    "    for idx, doc in enumerate(docs):\n",
    "        img_path = doc[\"image_path\"]\n",
    "        segments = doc[\"segments\"]\n",
    "        H, W = doc[\"dimensions\"]\n",
    "\n",
    "        # Copy image\n",
    "        img_out = f\"{out_dir}/images/{idx}.jpg\"\n",
    "        import shutil\n",
    "        shutil.copy2(img_path, img_out)\n",
    "\n",
    "        # Write YOLO label file (all segments = class 0)\n",
    "        label_out = f\"{out_dir}/labels/{idx}.txt\"\n",
    "        with open(label_out, \"w\") as f:\n",
    "            for seg in segments:\n",
    "                box = seg[\"box\"]\n",
    "                x_min = box[\"x_min\"]\n",
    "                y_min = box[\"y_min\"]\n",
    "                x_max = box[\"x_max\"]\n",
    "                y_max = box[\"y_max\"]\n",
    "\n",
    "                # Normalize YOLO format\n",
    "                x_center = (x_min + x_max) / 2 / W\n",
    "                y_center = (y_min + y_max) / 2 / H\n",
    "                w = (x_max - x_min) / W\n",
    "                h = (y_max - y_min) / H\n",
    "\n",
    "                # YOLO only needs class_id=0 for all\n",
    "                f.write(f\"0 {x_center} {y_center} {w} {h}\\n\")\n",
    "\n",
    "    print(\"YOLO segment-only dataset created!\", out_dir)\n",
    "\n",
    "convert_segments_to_yolo(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf3adaf-9bb9-42b5-a6c9-3a41bf22e9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv0.0.4 üöÄ Python-3.13.5 torch-2.9.1+cu128 CUDA:0 (NVIDIA A100-SXM4-80GB, 81038MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=../models/yolo.pt, data=../data/yolo_segments.yaml, epochs=50, time=None, patience=20, batch=8, imgsz=1024, save=True, save_period=10, val_period=1, cache=False, device=cuda, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/compiling-ganesh/24m0797/workspace/doctr-dit/runs/detect/train\n",
      "Overriding model.yaml nc=10 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  doclayout_yolo.nn.modules.conv.Conv          [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  doclayout_yolo.nn.modules.conv.Conv          [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  doclayout_yolo.nn.modules.block.C2f          [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  doclayout_yolo.nn.modules.conv.Conv          [96, 192, 3, 2]               \n",
      "  4                  -1  4   1778688  doclayout_yolo.nn.modules.g2l_crm.G2L_CRM    [192, 192, 4, True, True, [1, 2, 3], 5, 'glu']\n",
      "  5                  -1  1     78720  doclayout_yolo.nn.modules.block.SCDown       [192, 384, 3, 2]              \n",
      "  6                  -1  4   4737024  doclayout_yolo.nn.modules.g2l_crm.G2L_CRM    [384, 384, 4, True, True, [1, 3, 5], 3, 'glu']\n",
      "  7                  -1  1    228672  doclayout_yolo.nn.modules.block.SCDown       [384, 576, 3, 2]              \n",
      "  8                  -1  4   2714112  doclayout_yolo.nn.modules.g2l_crm.G2L_CRM    [576, 576, 4, True, False]    \n",
      "  9                  -1  1    831168  doclayout_yolo.nn.modules.block.SPPF         [576, 576, 5]                 \n",
      " 10                  -1  1   1253088  doclayout_yolo.nn.modules.block.PSA          [576, 576]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  doclayout_yolo.nn.modules.conv.Concat        [1]                           \n",
      " 13                  -1  2   1993728  doclayout_yolo.nn.modules.block.C2f          [960, 384, 2]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  doclayout_yolo.nn.modules.conv.Concat        [1]                           \n",
      " 16                  -1  2    517632  doclayout_yolo.nn.modules.block.C2f          [576, 192, 2]                 \n",
      " 17                  -1  1    332160  doclayout_yolo.nn.modules.conv.Conv          [192, 192, 3, 2]              \n",
      " 18            [-1, 13]  1         0  doclayout_yolo.nn.modules.conv.Concat        [1]                           \n",
      " 19                  -1  2    831744  doclayout_yolo.nn.modules.block.C2fCIB       [576, 384, 2, True]           \n",
      " 20                  -1  1    152448  doclayout_yolo.nn.modules.block.SCDown       [384, 384, 3, 2]              \n",
      " 21            [-1, 10]  1         0  doclayout_yolo.nn.modules.conv.Concat        [1]                           \n",
      " 22                  -1  2   1911168  doclayout_yolo.nn.modules.block.C2fCIB       [960, 576, 2, True]           \n",
      " 23        [16, 19, 22]  1   1829406  doclayout_yolo.nn.modules.head.v10Detect     [1, [192, 384, 576]]          \n",
      "YOLOv10m-doclayout summary: 635 layers, 19510446 parameters, 19510446 gradients, 66.1 GFLOPs\n",
      "\n",
      "Transferred 966/1050 items from pretrained weights\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/home/compiling-ganesh/24m0797/workspace/doctr-dit/notebooks/wandb/offline-run-20251125_230449-eo128m3e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/doclayout_yolo/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks skipped ‚ö†Ô∏è, offline and unable to download YOLOv8n. Setting 'amp=True'. If you experience zero-mAP or NaN losses you can disable AMP with amp=False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/compiling-ganesh/24m0797/workspace/doctr-dit/.venv/lib/python3.13/site-packages/doclayout_yolo/engine/trainer.py:277: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/compiling-ganesh/24m0797/workspace/doctr-dit/data/yolo_segments/labels... 995 images, 0 backgrounds, 1 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 995/995 [00:00<00:00, 1043.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/compiling-ganesh/24m0797/workspace/doctr-dit/data/yolo_segments/images/145.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.1913536 1.0420649 1.1729534 1.125281  1.1158383 1.1422107 1.1216625\n",
      " 1.1487547 1.1511207 1.132253  1.1215011 1.1261437 1.1661302 1.114101\n",
      " 1.1600661 1.1063203 1.1306188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/compiling-ganesh/24m0797/workspace/doctr-dit/data/yolo_segments/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/compiling-ganesh/24m0797/workspace/doctr-dit/.venv/lib/python3.13/site-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "  data = fetch_version_info()\n",
      "/home/compiling-ganesh/24m0797/workspace/doctr-dit/.venv/lib/python3.13/site-packages/doclayout_yolo/data/augment.py:846: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
      "  A.ImageCompression(quality_lower=75, p=0.0),\n",
      "/home/compiling-ganesh/24m0797/workspace/doctr-dit/.venv/lib/python3.13/site-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n",
      "/home/compiling-ganesh/24m0797/workspace/doctr-dit/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/compiling-ganesh/24m0797/workspace/doctr-dit/data/yolo_segments/labels.cache... 995 images, 0 backgrounds, 1 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 995/995 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/compiling-ganesh/24m0797/workspace/doctr-dit/data/yolo_segments/images/145.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.1913536 1.0420649 1.1729534 1.125281  1.1158383 1.1422107 1.1216625\n",
      " 1.1487547 1.1511207 1.132253  1.1215011 1.1261437 1.1661302 1.114101\n",
      " 1.1600661 1.1063203 1.1306188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/compiling-ganesh/24m0797/workspace/doctr-dit/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/compiling-ganesh/24m0797/workspace/doctr-dit/runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 171 weight(decay=0.0), 183 weight(decay=0.0005), 183 bias(decay=0.0)\n",
      "Image sizes 1024 train, 1024 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/compiling-ganesh/24m0797/workspace/doctr-dit/runs/detect/train\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      17.8G      3.036      1.974          0       2.98      3.605          0        146       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [01:23<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:15<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "                   all        994      19299        0.5      0.557      0.463      0.202\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      18.1G      1.766      1.002          0      1.965      1.289          0         46       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:40<00:00,  3.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "                   all        994      19299      0.699      0.668       0.68      0.347\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      18.1G      1.434     0.8509          0      1.642       1.08          0        122       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:40<00:00,  3.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "                   all        994      19299      0.783      0.738      0.789      0.475\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      18.6G      1.277     0.7711          0      1.497     0.9377          0         23       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:39<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "                   all        994      19299      0.803      0.764      0.822      0.505\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      18.2G      1.179     0.7273          0      1.422     0.8701          0        113       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:39<00:00,  3.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "                   all        994      19299      0.825      0.785      0.842      0.541\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      18.7G      1.107      0.676          0      1.341     0.8041          0        131       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:39<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "                   all        994      19299      0.848      0.798      0.862      0.577\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      17.9G      1.069     0.6567          0      1.298     0.7676          0         70       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:39<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "                   all        994      19299      0.858      0.823      0.873       0.59\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      17.6G      1.041      0.641          0      1.281     0.7533          0         29       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:39<00:00,  3.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "                   all        994      19299      0.864      0.835      0.883      0.603\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      18.3G      1.011     0.6115          0       1.25     0.7184          0         62       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:39<00:00,  3.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "                   all        994      19299      0.864      0.834      0.889      0.605\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      18.3G      1.011     0.6153          0      1.237     0.7253          0         54       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:39<00:00,  3.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "                   all        994      19299      0.866      0.847      0.891      0.641\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      18.6G     0.9966     0.6036          0      1.223      0.676          0         31       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:40<00:00,  3.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "                   all        994      19299      0.878      0.856      0.903      0.639\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      17.8G      0.984     0.5998          0      1.192     0.6723          0         65       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:40<00:00,  3.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "                   all        994      19299      0.882      0.862      0.906      0.644\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      17.5G     0.9618     0.5842          0      1.174     0.6529          0        146       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:39<00:00,  3.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "                   all        994      19299      0.892      0.864      0.913      0.649\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50        18G     0.9224     0.5625          0      1.129     0.6167          0        301       1024:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 120/125 [00:38<00:01,  3.06it/s]"
     ]
    }
   ],
   "source": [
    "# train_yolo.py\n",
    "from doclayout_yolo import YOLOv10\n",
    "\n",
    "def train_yolo():\n",
    "    model = YOLOv10(\"../models/yolo.pt\")   # lightweight and fast\n",
    "\n",
    "    model.train(\n",
    "        data=\"../data/yolo_segments.yaml\",\n",
    "        epochs=50,\n",
    "        imgsz=1024,\n",
    "        batch=8,\n",
    "        device=\"cuda\",\n",
    "        lr0=0.001,\n",
    "        optimizer=\"AdamW\",\n",
    "        patience=20,\n",
    "    )\n",
    "\n",
    "    model.save(\"../models/yolo_segments_trained.pt\")\n",
    "    print(\"Training complete! Saved model as yolo_segments_trained.pt\")\n",
    "\n",
    "train_yolo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
